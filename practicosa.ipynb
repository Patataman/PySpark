{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "is_conda = os.path.exists(os.path.join(sys.prefix, 'conda-meta'))\n",
    "\n",
    "if not is_conda:\n",
    "    import findspark \n",
    "    findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from pyspark.sql.functions import col, datediff, unix_timestamp\n",
    "import csv\n",
    "from IPython.core.display import display, HTML\n",
    "from IPython.display import IFrame\n",
    "from collections import defaultdict\n",
    "\n",
    "# Para una lectura más distendida de la memoria\n",
    "MODO_JAJAS = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODO_JAJAS:\n",
    "    display(IFrame(\"https://giphy.com/embed/I1U9DTjCqOF3i\",width=\"240\", height=\"135\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"taxis\").master(\"local[*]\").getOrCreate()\n",
    "df = spark.read.csv('./tripdata_2017_01.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()\n",
    "dfP=df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dfP)\n",
    "display(dfP.describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODO_JAJAS:\n",
    "    display(IFrame(\"https://giphy.com/embed/xsATxBQfeKHCg\", width=\"240\", height=\"180\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elementos extraños en el dataset\n",
    "\n",
    "Lista de comportamientos extraños en los datos, y por tanto, inválidos a la hora de utilizar datos que deberían ser coherentes basándonos en la información de cada campo proporcionada por la [documentación](https://www1.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf)\n",
    "\n",
    "* Existen carreras en las que la distancia es 0\n",
    "* Existen propinas negativas\n",
    "* \"extra\" con valores diferentes a 0 (ya que puede no haber extras), 0.5 y 1\n",
    "* Existen viajes con un precio final negativo\n",
    "* \"MTA_tax\" debe valer siempre 0.50. Valores diferentes son erróneos, y por tanto puede que el resto de la información también\n",
    "    * De forma similar, \"Improvement_surcharge\" no debe valer menos de 0.30\n",
    "* Carreras cuya fecha de fin sea igual o anterior a la fecha de inicio\n",
    "* Existen tarifas con valores negativos. No tiene sentido ya que la tarifa va en función del tiempo y la distancia recorridas\n",
    "* \"Improvement_surcharge\" es un valor en desuso, por lo que debería valer en el menor caso 0, no -0.3\n",
    "\n",
    "### Elementos extraños PERO posibles\n",
    "\n",
    "* Número de pasajeros es 0. Dado que es un valor que introduce el propio conductor, muy probablemente le de bastante igual introducir bien el valor.\n",
    "* Un viaje empieza y acaba en la misma zona.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza realizada\n",
    "\n",
    "A partir de los comportamientos observados se ha procedido a eliminar las carreras que cumplen las siguientes condiciones:\n",
    "\n",
    "- Campo \"tip_amount\" con valores menor a 0\n",
    "- Campo \"total_amount\" con valores menor o igual a 0\n",
    "- Campo \"trip_distance\" con valores menor o igual a 0\n",
    "- Campo \"fare_amount\" con valores menor o igual a 0\n",
    "- Campo \"extra\" con valores diferentes de 0, 0.5 y 1\n",
    "- Campo \"MTA_tax\" con valor distinto de 0.5\n",
    "- Campo \"Improvement_surcharge\" con valor distinto de 0 o 0.3\n",
    "- Campo \"tpep_dropoff_datetime\" es anterior o igual a \"tpep_pickup_datetime\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos las fechas a timestamp, para que dejen de ser strings a secas\n",
    "# y guardamos su diferencia para luego tener más fácil el filtrado y otros cálculos\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"tpep_pickup_timestamp\", unix_timestamp(col(\"tpep_pickup_datetime\").cast(\"timestamp\"))\n",
    ").withColumn(\n",
    "    \"tpep_dropoff_timestamp\", unix_timestamp(col(\"tpep_dropoff_datetime\").cast(\"timestamp\"))\n",
    ").withColumn(\n",
    "    \"time_diff\", col(\"tpep_dropoff_timestamp\") - col(\"tpep_pickup_timestamp\")  # Segundos\n",
    ")\n",
    "\n",
    "df.createOrReplaceTempView('datosCarreras')\n",
    "# display(df.toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datosLimpios = spark.sql(\"\"\"\n",
    "    SELECT * FROM datosCarreras WHERE\n",
    "        tip_amount >= 0 AND\n",
    "        total_amount > 0 AND\n",
    "        trip_distance > 0 AND\n",
    "        fare_amount > 0 AND\n",
    "        (extra == 0 OR extra == 0.5 OR extra == 1) AND\n",
    "        mta_tax == 0.5 AND\n",
    "        improvement_surcharge >= 0 AND\n",
    "        time_diff > 0\n",
    "\"\"\")\n",
    "# print(datosLimpios.count())\n",
    "datosLimpios.createOrReplaceTempView('datosCarrerasLimpios')\n",
    "# datosLimpiosP = datosLimpios.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# display(datosLimpiosP)\n",
    "# display(datosLimpiosP.describe().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracción de información\n",
    "\n",
    "Ahora que ya hemos limpiado los datos y tenemos entradas coherentes, se puede proceder a extraer información de los mismos. \n",
    "\n",
    "La información que se va a extraer es:\n",
    "\n",
    "* Velocidad media de los taxis en función de la hora.\n",
    "* Viajes en taxi más comunes\n",
    "* Registros financieros (propinas, personas, etc.)\n",
    "    * Timos a turistas\n",
    "    * Propinas en función de la hora\n",
    "    * Identificar pasajeros borrachos\n",
    "* Zonas con poca cobertura\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bajamos el csv con la información de las zonas para luego poder \"traducir\"\n",
    "if not os.path.exists(\"taxi+_zone_lookup.csv\"):\n",
    "    !wget https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se añade al dataframe los datos de las zonas de subida y bajada. Para ello se va a realizar un join,\n",
    "# De forma que vaya dentro del dataframe y es accesible también desde un rdd\n",
    "\n",
    "df_lookup = spark.read.csv('./taxi+_zone_lookup.csv', header=True, inferSchema=False)\n",
    "\n",
    "datosLimpios = datosLimpios.withColumn(\"LocationID\", col(\"PULocationID\")\n",
    ").join(\n",
    "    # Renombramos para poder luego incluir también las de bajada\n",
    "    df_lookup.withColumnRenamed(\"Borough\", \"PUBorough\"\n",
    "            ).withColumnRenamed(\"Zone\", \"PUZone\"\n",
    "            ).withColumnRenamed(\"service_zone\", \"PUservice_zone\"),\n",
    "    on=['LocationID']\n",
    ").withColumn(\"LocationID\", col(\"DOLocationID\")\n",
    ").join(\n",
    "    df_lookup.withColumnRenamed(\"Borough\", \"DOBorough\"\n",
    "            ).withColumnRenamed(\"Zone\", \"DOZone\"\n",
    "            ).withColumnRenamed(\"service_zone\", \"DOservice_zone\"),\n",
    "    on=['LocationID']\n",
    ")\n",
    "\n",
    "datosLimpios.createOrReplaceTempView('datosCarrerasLimpios')\n",
    "\n",
    "# datosLimpiosP = datosLimpios.toPandas()\n",
    "# display(datosLimpiosP)\n",
    "# display(datosLimpiosP.describe().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Velocidad media de los taxis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este apartado se realizará un análisis de la velocidad media de los taxis, para ello se realizará una transformación de millas a metros sabiendo que 1 milla = 1609.344 metros luego dividiéndolo entre la diferencia de tiempo calculada previamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMTS = datosLimpios.withColumn(\n",
    "    \"mean_speed\", col(\"trip_distance\")*1609.344/col(\"time_diff\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfMTSP = dfMTS.toPandas()\n",
    "display(dfMTSP.sort_values(by=[\"mean_speed\"],ascending=False).head(50))\n",
    "display(dfMTSP.describe().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En vista de que las velocidades medias estaban mal y esto, como se puede ver en la tabla, es debido a que el time_diff es muy bajo, probablemente por un error de los tiempos almacenador por los taxistas, por lo tanto se volverá a realizar una consulta eliminando tiempos menores a 3 minutos y se comprobará las velocidades promedio otra vez.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datosLimpiosSinVelocidades = spark.sql(\"SELECT * FROM datosCarrerasLimpios where time_diff >= 180\")\n",
    "dfMTS = datosLimpiosSinVelocidades.withColumn(\n",
    "    \"mean_speed\", col(\"trip_distance\")*1609.344/col(\"time_diff\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resultsTolls = spark.sql(\"SELECT * FROM datosCarrerasLimpios where tolls_amount > 100\").toPandas()\n",
    "display(resultsTolls)\n",
    "display(resultsTolls.describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsTimos = spark.sql(\"SELECT * FROM datosCarrerasLimpios where PULocationID == DOLocationID\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMTSP = dfMTS.toPandas()\n",
    "display(dfMTSP.sort_values(by=[\"mean_speed\"],ascending=False).head(50))\n",
    "display(dfMTSP.describe().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### [referenica a velocidades medias]\n",
    "\n",
    "Como se puede observar, la mayoría de velocidades entre las 50 más rápidas superan el límite de velocidad nacional para zonas de carretera (24.72222 m/s) siendo que solo los 5 últimos lo cumplen, o en otras palabras que los 45 primeros infringen la ley.\n",
    "\n",
    "Por otro lado se puede ver que los 8 primeros tienen velocidades mayores a 52 metros por segundo, lo que implica velocidades de 187.2 km/s esto puede ser debido a que haya algún tipo de fallo en el tiempo o que lleve velocidades demasiado altas.\n",
    "\n",
    "Por último mencionar que los 6 primeros tienen velocidades mayores a 65 m/s, cosa que ya debe ser debido a un fallo, accidental o adrede por parte del conductor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zonas de poca cobertura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando la variable `store_and_fwd_flag`, creemos que es posible deducir qué zonas de la ciudad de Nueva York dan un mayor problema a la hora de estar conectados con el servidor de la compañía de taxis, es decir, tienen poca cobertura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODO_JAJAS:\n",
    "    display(IFrame(\"https://giphy.com/embed/PmdOx0iRRtqkBFlEgI\", width=\"240\", height=\"240\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sinCobertura_rdd = spark.sql(\"\"\"\n",
    "    SELECT DOBorough, DOZone\n",
    "      FROM datosCarrerasLimpios\n",
    "      WHERE store_and_fwd_flag == 'Y'\n",
    "\"\"\").rdd\n",
    "\n",
    "# sC_rdd.flatMap(lambda x: x['locationID']).map(lambda x: (x,1))\n",
    "zone_tuples = sinCobertura_rdd.map(\n",
    "    lambda x: (x['DOZone'],1)\n",
    ").reduceByKey(\n",
    "    lambda x,y: x+y\n",
    ").sortBy(\n",
    "    lambda x: x[1], False\n",
    ")\n",
    "borough_tuples = sinCobertura_rdd.map(\n",
    "    lambda x: (x['DOBorough'],1)\n",
    ").reduceByKey(\n",
    "    lambda x,y: x+y\n",
    ").sortBy(\n",
    "    lambda x: x[1], False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autolabel(rects):\n",
    "    # https://matplotlib.org/3.1.1/gallery/lines_bars_and_markers/barchart.html#sphx-glr-gallery-lines-bars-and-markers-barchart-py\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\", fontsize=25,\n",
    "                    ha='center', va='bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zonas = zone_tuples.take(10)\n",
    "distritos = borough_tuples.take(10)\n",
    "\n",
    "distritos_x = [k for k, v in distritos]\n",
    "distritos_y = [v for k, v in distritos]\n",
    "zonas_x = [k for k, v in zonas]\n",
    "zonas_y = [v for k, v in zonas]\n",
    "\n",
    "fig = plt.figure(figsize=(30, 10))\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "rects1 = ax.bar(distritos_x, distritos_y)\n",
    "ax.set_xlabel(\"Distrito\", fontsize=25)\n",
    "ax.set_ylabel(\"Registros guardados\", fontsize=25)\n",
    "ax.set_title(\"Registros guardados por distritos\", fontsize=25)\n",
    "plt.xticks(rotation=90, fontsize=25)\n",
    "plt.yticks(fontsize=25)\n",
    "autolabel(rects1)\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "rects2 = ax.bar(zonas_x, zonas_y)\n",
    "ax.set_xlabel(\"Zona\", fontsize=25)\n",
    "ax.set_ylabel(\"Registros guardados\", fontsize=25)\n",
    "ax.set_title(\"Registros guardados por zonas\", fontsize=25)\n",
    "plt.xticks(rotation=90, fontsize=25)\n",
    "plt.yticks(fontsize=25)\n",
    "autolabel(rects2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viajes_manhattan = spark.sql(\"\"\"\n",
    "    SELECT VendorID\n",
    "      FROM datosCarrerasLimpios\n",
    "      WHERE DOBorough == 'Manhattan'\n",
    "\"\"\").count()\n",
    "int(distritos_y[0])/int(viajes_manhattan)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede apreciar por el número de registros guardados en los taxis, Manhattan es el distrito que tiene más registros guardados con 2490, casi 5 veces más que su distrito posterior, Queens con 435. Por lo que se puede deducir que tiene zonas frecuentadas en las que no se tiene cobertura.\n",
    "\n",
    "Sin embargo, es un porcentaje pequeño sobre el total, ya que representan menos del 0.3% de todos los viajes existentes que finalizan en Manhattan, por lo que muy probablemente se deba a taxis concretos que tienen problemas de conexión.\n",
    "\n",
    "Observando que se trata de un porcentaje muy bajo, surge otra pregunta: ¿En qué momento se guardaron los registros? ¿Todos los registros guardados son en horas similares y por tanto puede deberse a una caída del servidor más que a un problema de cobertura?\n",
    "\n",
    "Para ello se van a observar los registros de Manhattan ya que son los más numerosos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stored_manhattan = spark.sql(\"\"\"\n",
    "    SELECT tpep_dropoff_datetime, DAY(tpep_dropoff_datetime) as day, HOUR(tpep_dropoff_datetime) as hour\n",
    "      FROM datosCarrerasLimpios\n",
    "      WHERE store_and_fwd_flag == 'Y' and DOBorough == 'Manhattan'\n",
    "\"\"\")\n",
    "\n",
    "# Nos vamos a quedar con el día con mayor número de registros guardados\n",
    "day, count = stored_manhattan.groupBy(\"day\").count().sort(\"count\").tail(1)[0]\n",
    "\n",
    "# Ahora que tenemos el día, podemos ver las horas en las que se agruparon los mensajes.\n",
    "# Si todos (o casi todos) los mensajes se agruparon en la misma hora, eso significa \n",
    "# (muy probablemente) que hubo una caída del servidor\n",
    "mensajes_hora = stored_manhattan.filter(col(\"day\")==day).groupBy(\"hour\").count().collect()\n",
    "\n",
    "mensajes_x = [h for h, cnt in mensajes_hora]\n",
    "mensajes_y = [cnt for h, cnt in mensajes_hora]\n",
    "\n",
    "fig = plt.figure(figsize=(30, 10))\n",
    "\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "rects1 = ax.bar(mensajes_x, mensajes_y)\n",
    "ax.set_xlabel(\"Horas\", fontsize=25)\n",
    "ax.set_ylabel(\"Mensajes\", fontsize=25)\n",
    "ax.set_title(\"Mensajes guardados por hora\", fontsize=25)\n",
    "plt.xticks(rotation=90, fontsize=25)\n",
    "plt.yticks(fontsize=25)\n",
    "autolabel(rects1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los mensajes guardados se agrupan entre las 10 AM y las 21 PM, pero dado que se corresponde también con el periodo de actividad de los taxis, porque es cuando la gran mayoría de la población se desplaza por la ciudad, no parece que se deba a una caída del servidor.\n",
    "\n",
    "Por lo tanto nos reafirmamos en la primera suposición: **Muy probablemente se debe a taxis concretos que tienen problemas de conexión**, no ha una caída generalizada. Además si hubiese sido ese el caso, el número de registros debería haber sido muchísimo mayor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viajes más comunes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IDEAS\n",
    "\n",
    "propinas / hora\n",
    "\n",
    "Timos\n",
    "\n",
    "- Vueltas de mas en misma zona\n",
    "- Tolls valores raros\n",
    "- Diferencias exageradas de distancias para pares de datos con mismo origen y destino\n",
    "\n",
    "Velocidad media de los taxis en función de la hora.\n",
    "\n",
    "Viajes en taxi más comunes\n",
    "\n",
    "Registros financieros (propinas, personas, etc.)\n",
    "\n",
    "Zonas sin cobertura a partir del parámetro Store_and_fwd_flag\n",
    "\n",
    "Fare_amount frente a time_diff y trip distance, infracciones de ley\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
